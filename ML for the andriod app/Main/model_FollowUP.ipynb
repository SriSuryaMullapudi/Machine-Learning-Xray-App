{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load features and labels\n",
    "X =  np.load('Feature_Concatenation_MobileNet.npy')\n",
    "X = X.reshape(X.shape[0],X.shape[2]*4)\n",
    "y = np.load('Labels.npy')\n",
    "\n",
    "#dataset split\n",
    "X_train = X[:111]\n",
    "X_val = X[111:-32]\n",
    "X_test = X[-32:]\n",
    "y_train = y[:111]\n",
    "y_val = y[111:-32]\n",
    "y_test = y[-32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#example of training baseline model\n",
    "clf1 = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "clf2 = GradientBoostingClassifier(random_state=0).fit(X_train, y_train)\n",
    "clf3 = RandomForestClassifier(random_state=0).fit(X_train, y_train)\n",
    "#Number of “Worse” versus “Improved” case in testing dataset:\n",
    "N = y_test.size-(y_test==0).sum()\n",
    "#Classification accuracy of discriminating “Worse” versus “Improved” case\n",
    "print((clf1.predict(X_test)*y_test == 1).sum()/N)\n",
    "print((clf2.predict(X_test)*y_test == 1).sum()/N)\n",
    "print((clf3.predict(X_test)*y_test == 1).sum()/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FC-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load features and labels\n",
    "X =  np.load('Feature_Concatenation_MobileNet.npy')\n",
    "X = X.reshape(X.shape[0],X.shape[2]*4)\n",
    "y = np.load('Labels.npy')\n",
    "#reassign the label to positive\n",
    "y[y<0]=2\n",
    "\n",
    "#dataset split\n",
    "X_train = X[:111]\n",
    "X_val = X[111:-32]\n",
    "X_test = X[-32:]\n",
    "y_train = y[:111]\n",
    "y_val = y[111:-32]\n",
    "y_test = y[-32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MyDataset(X_train,y_train)\n",
    "dataset_val = MyDataset(X_val,y_val)\n",
    "dataset_test = MyDataset(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "valloader = DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=5,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "testloader = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(feature_size,300)\n",
    "        self.fc2 = nn.Linear(300, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, feature_size)\n",
    "        emb = F.relu(self.fc1(x))\n",
    "        nn.Dropout(0.5), #50 % probability \n",
    "        x = self.fc2(emb)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs=100\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "   \n",
    "    model.train()\n",
    "    for inputs, labels in trainloader:\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)#+criterion1()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    results = []\n",
    "    gt = []\n",
    "    running_corrects = 0\n",
    "\n",
    "    model.eval()\n",
    "    results = []\n",
    "    gt = []\n",
    "    running_corrects = 0\n",
    "    for inputs, labels in testloader:\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        results.append(preds.data.numpy())\n",
    "        gt.append(labels.data.numpy())\n",
    "    results = np.hstack(results)\n",
    "    gt = np.hstack(gt)\n",
    "    index = [gt!=0]\n",
    "    print('test')\n",
    "    print((results[index] == gt[index]).sum()/(gt!=0).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('pytorch13py37': conda)",
   "language": "python",
   "name": "python37064bitpytorch13py37conda8276faef4ca54a609119653f6cb51cde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}